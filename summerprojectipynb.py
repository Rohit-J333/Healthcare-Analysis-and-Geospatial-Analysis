# -*- coding: utf-8 -*-
"""summerprojectipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14YTdLLAvkVfVo8V1wbjHPeLsvJa3mdYn

# Random Forest for regression withour patient dispostion
"""

!pip install shap

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim

from torch.utils.data import Dataset,DataLoader, random_split
import math
from sklearn.ensemble import RandomForestRegressor

df = pd.read_csv("https://health.data.ny.gov/api/views/4ny4-j5zv/rows.csv?accessType=DOWNLOAD")
r = int(df.shape[0] * 0.1)
print(r)

def transform_data(df):

  #clean data
  df = df.dropna(subset=['Hospital Service Area','Hospital County','Operating Certificate Number',
                      'Permanent Facility Id','Zip Code - 3 digits',
                      'APR Severity of Illness Description','APR Risk of Mortality'])
  df.drop(['CCSR Diagnosis Description', 'CCSR Procedure Description','Discharge Year', 'APR DRG Description', 'APR MDC Description', 'Total Costs', 'Total Charges',
                 'APR Severity of Illness Description','Payment Typology 2','Payment Typology 3','Race','Gender','Birth Weight','Patient Disposition'], axis=1, inplace=True)

  ga = math.pow(10,-15)
  df.loc[:, 'Length of Stay'] = df['Length of Stay'].replace('120 +',120)
  df.loc[:, 'Length of Stay'] = df['Length of Stay'].astype(np.int)


  df = df.sample(frac=1)

  names = df.columns
  n = len(names)
  i = 0
  names1 = []
  def remove(string):
    return string.replace(" ", "")
  while(i < n):
      s = remove(names[i])
      if(s == "ZipCode-3digits"):
          s = "ZipCodedigits"
      names1.append(s)
      i = i+1

  #encoding data

  df.columns = names1
  obj_columns = df.select_dtypes(include=['object']).columns



  for col in obj_columns:
      try:
        uniq_values = df[col].unique()
      except:
        print("the column giving error is, "+ col)
        break
      mapping = {k: v for v, k in enumerate(uniq_values)}
      df[col] = df[col].map(mapping)
      try:
          geeky_file = open('encodings.txt', 'a+')
          geeky_file.write("\n\n"+col+"\n"+str(mapping))
          geeky_file.close()

      except Exception as e:
          print(e)
          print("Unable to append to file")



  return df.drop("LengthofStay", axis = 1).values, df['LengthofStay'].values, df.drop("LengthofStay", axis=1).columns

print(df.columns)

X, Y, cols = transform_data(df)

train_X = X[:r*9,:]
train_Y = Y[:r*9]
test_X = X[r*9:,:]
test_Y = Y[r*9:]

rf = RandomForestRegressor(n_estimators=10, max_depth = 10)

rf.fit(train_X, train_Y)

rf.score(test_X, test_Y)

cv_score = np.mean((cross_val_score(rf, df.iloc[1:, :-1], df.iloc[1:, -1], cv=5)))
print(f"cross validation score using random forest regressor {cv_score}")

!pip install shap

from shap import TreeExplainer
import shap

explainer = TreeExplainer(rf)
random_sample = test_X[np.random.randint(test_X.shape[0], size=50)]
shap_values = explainer.shap_values(random_sample)

shap.initjs()
shap.force_plot(explainer.expected_value, shap_values[0,:], random_sample[0,:], feature_names = cols)

shap.summary_plot(shap_values, random_sample, feature_names=cols)

"""# Xgboost regressor without patient disposition"""

!pip install xgboost
!pip install shap

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import xgboost as xg
from torch.utils.data import Dataset,DataLoader, random_split
from sklearn import metrics
import math

def transform_data(df):

  #clean data
  df = df.dropna(subset=['Hospital Service Area','Hospital County','Operating Certificate Number',
                      'Permanent Facility Id','Zip Code - 3 digits',
                      'APR Severity of Illness Description','APR Risk of Mortality'])
  df.drop(['CCSR Diagnosis Description', 'CCSR Procedure Description','Discharge Year', 'APR DRG Description', 'APR MDC Description', 'Total Costs', 'Total Charges',
                 'APR Severity of Illness Description','Payment Typology 2','Payment Typology 3','Race','Gender','Birth Weight','Patient Disposition'], axis=1, inplace=True)

  ga = math.pow(10,-15)
  df.loc[:, 'Length of Stay'] = df['Length of Stay'].replace('120 +',120)
  df.loc[:, 'Length of Stay'] = df['Length of Stay'].astype(np.int)

  df = df.sample(frac=1)

  names = df.columns
  n = len(names)
  i = 0
  names1 = []
  def remove(string):
    return string.replace(" ", "")
  while(i < n):
      s = remove(names[i])
      if(s == "ZipCode-3digits"):
          s = "ZipCodedigits"
      names1.append(s)
      i = i+1

  #encoding data

  df.columns = names1

  obj_columns = df.select_dtypes(include=['object']).columns

  for col in obj_columns:
      try:
        uniq_values = df[col].unique()
      except:
        print("the column giving error is, "+ col)
        break
      mapping = {k: v for v, k in enumerate(uniq_values)}
      df[col] = df[col].map(mapping)
      try:
          geeky_file = open('encodings.txt', 'a+')
          geeky_file.write("\n\n"+col+"\n"+str(mapping))
          geeky_file.close()

      except Exception as e:
          print(e)
          print("Unable to append to file")

  return df.drop("LengthofStay", axis = 1).values, df['LengthofStay'].values, df.drop("LengthofStay", axis=1).columns

df = pd.read_csv("https://health.data.ny.gov/api/views/4ny4-j5zv/rows.csv?accessType=DOWNLOAD")
r = int(df.shape[0] * 0.1)
print(r)

X, Y, cols = transform_data(df)

train_X = X[:r*9,:]
train_Y = Y[:r*9]
test_X = X[r*9:,:]
test_Y = Y[r*9:]

xgb_r = xg.XGBRegressor(objective ='reg:linear', n_estimators = 10, seed = 123)

xgb_r.fit(train_X, train_Y)
pred = xgb_r.predict(test_X)
r2 = metrics.r2_score(test_Y, pred)
print(f"r2 score = {r2}")

from shap import TreeExplainer
import shap

explainer = TreeExplainer(rf)
random_sample = test_X[np.random.randint(test_X.shape[0], size=50)]
shap_values = explainer.shap_values(random_sample)

shap.summary_plot(shap_values, random_sample, feature_names=cols)

"""# Xgboost regressor with patient disposition"""

!pip install xgboost

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import xgboost as xg
from torch.utils.data import Dataset,DataLoader, random_split
from sklearn import metrics
import math

def transform_data(df):

  #clean data
  df = df.dropna(subset=['Hospital Service Area','Hospital County','Operating Certificate Number',
                      'Permanent Facility Id','Zip Code - 3 digits',
                      'APR Severity of Illness Description','APR Risk of Mortality'])
  df.drop(['CCSR Diagnosis Description', 'CCSR Procedure Description','Discharge Year', 'APR DRG Description', 'APR MDC Description', 'Total Costs', 'Total Charges',
                 'APR Severity of Illness Description','Payment Typology 2','Payment Typology 3','Race','Gender','Birth Weight'], axis=1, inplace=True)

  ga = math.pow(10,-15)
  df.loc[:, 'Length of Stay'] = df['Length of Stay'].replace('120 +',120)
  df.loc[:, 'Length of Stay'] = df['Length of Stay'].astype(np.int)

  df = df.sample(frac=1)

  names = df.columns
  n = len(names)
  i = 0
  names1 = []
  def remove(string):
    return string.replace(" ", "")
  while(i < n):
      s = remove(names[i])
      if(s == "ZipCode-3digits"):
          s = "ZipCodedigits"
      names1.append(s)
      i = i+1

  #encoding data

  df.columns = names1

  obj_columns = df.select_dtypes(include=['object']).columns

  for col in obj_columns:
      try:
        uniq_values = df[col].unique()
      except:
        print("the column giving error is, "+ col)
        break
      mapping = {k: v for v, k in enumerate(uniq_values)}
      df[col] = df[col].map(mapping)
      try:
          geeky_file = open('encodings.txt', 'a+')
          geeky_file.write("\n\n"+col+"\n"+str(mapping))
          geeky_file.close()

      except Exception as e:
          print(e)
          print("Unable to append to file")

  return df.drop("LengthofStay", axis = 1).values, df['LengthofStay'].values, df.drop("LengthofStay", axis=1).columns

df = pd.read_csv("https://health.data.ny.gov/api/views/4ny4-j5zv/rows.csv?accessType=DOWNLOAD")
r = int(df.shape[0] * 0.1)
print(r)

X, Y, cols = transform_data(df)

train_X = X[:r*9,:]
train_Y = Y[:r*9]
test_X = X[r*9:,:]
test_Y = Y[r*9:]

xgb_r = xg.XGBRegressor(objective ='reg:linear', n_estimators = 10, seed = 123)

xgb_r.fit(train_X, train_Y)
pred = xgb_r.predict(test_X)
r2 = metrics.r2_score(test_Y, pred)
print(f"r2 score = {r2}")



"""# Decision tree regressor without patient disposition"""

!pip install snap

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim

from torch.utils.data import Dataset,DataLoader, random_split
from sklearn import metrics
import math

from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import cross_val_score

def transform_data(df):

  #clean data
  df = df.dropna(subset=['Hospital Service Area','Hospital County','Operating Certificate Number',
                      'Permanent Facility Id','Zip Code - 3 digits',
                      'APR Severity of Illness Description','APR Risk of Mortality'])
  df.drop(['CCSR Diagnosis Description', 'CCSR Procedure Description','Discharge Year', 'APR DRG Description', 'APR MDC Description', 'Total Costs', 'Total Charges',
                 'APR Severity of Illness Description','Payment Typology 2','Payment Typology 3','Race','Gender','Birth Weight','Patient Disposition'], axis=1, inplace=True)

  ga = math.pow(10,-15)
  df.loc[:, 'Length of Stay'] = df['Length of Stay'].replace('120 +',120)
  df.loc[:, 'Length of Stay'] = df['Length of Stay'].astype(np.int)

  df = df.sample(frac=1)

  names = df.columns
  n = len(names)
  i = 0
  names1 = []
  def remove(string):
    return string.replace(" ", "")
  while(i < n):
      s = remove(names[i])
      if(s == "ZipCode-3digits"):
          s = "ZipCodedigits"
      names1.append(s)
      i = i+1

  #encoding data

  df.columns = names1

  obj_columns = df.select_dtypes(include=['object']).columns

  for col in obj_columns:
      try:
        uniq_values = df[col].unique()
      except:
        print("the column giving error is, "+ col)
        break
      mapping = {k: v for v, k in enumerate(uniq_values)}
      df[col] = df[col].map(mapping)
      try:
          geeky_file = open('encodings.txt', 'a+')
          geeky_file.write("\n\n"+col+"\n"+str(mapping))
          geeky_file.close()

      except Exception as e:
          print(e)
          print("Unable to append to file")

  return df.drop("LengthofStay", axis = 1).values, df['LengthofStay'].values, df.drop("LengthofStay", axis=1).columns

df = pd.read_csv("https://health.data.ny.gov/api/views/4ny4-j5zv/rows.csv?accessType=DOWNLOAD")
r = int(df.shape[0] * 0.1)
print(r)

X, Y, cols = transform_data(df)

train_X = X[:r*9,:]
train_Y = Y[:r*9]
test_X = X[r*9:,:]
test_Y = Y[r*9:]

regressor = DecisionTreeRegressor(random_state=0, max_depth=7, max_features="auto")
regressor.fit(train_X, train_Y, check_input=True)

pred = regressor.predict(test_X)
r2 = metrics.r2_score(test_Y, pred)
print(f"r2 score = {r2}")



"""# Age Wise"""

# @title Imports
!pip install shap
!pip install catboost
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn import linear_model
import shap
from sklearn.tree import DecisionTreeRegressor
from sklearn import metrics
from sklearn import preprocessing

from sklearn import tree
from matplotlib import pyplot as plt
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score
from sklearn import linear_model
import scipy.stats as ss
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
import itertools
from catboost import CatBoostRegressor
from catboost import CatBoostClassifier

# @title Data Preprocessing
df = pd.read_csv("https://health.data.ny.gov/api/views/4ny4-j5zv/rows.csv?accessType=DOWNLOAD")
r = int(df.shape[0] * 0.1)
print(r)
df = df.dropna(subset=['Hospital Service Area','Hospital County','Operating Certificate Number',
                      'Permanent Facility Id','Zip Code - 3 digits',
                      'APR Severity of Illness Description','APR Risk of Mortality'])
df.drop(['CCSR Diagnosis Description', 'CCSR Procedure Description','Discharge Year', 'APR DRG Description', 'APR MDC Description', 'Total Costs', 'Total Charges',
                 'APR Severity of Illness Description','Payment Typology 2','Payment Typology 3','Race','Gender','Birth Weight','Patient Disposition'], axis=1, inplace=True)

ga = math.pow(10,-15)
df.loc[:, 'Length of Stay'] = df['Length of Stay'].replace('120 +',120)
df.loc[:, 'Length of Stay'] = df['Length of Stay'].astype(np.int)

df = df.sample(frac=1)

names = df.columns
n = len(names)
i = 0
names1 = []
def remove(string):
  return string.replace(" ", "")
while(i < n):
     s = remove(names[i])
     if(s == "ZipCode-3digits"):
        s = "ZipCodedigits"
     names1.append(s)
     i = i+1


df.columns = names1

# @title Data transforming using Target Encoding
columns_to_target_encode = ["HospitalServiceArea", 'CCSRProcedureCode','CCSRDiagnosisCode','TypeofAdmission', 'APRRiskofMortality',
                            'APRMedicalSurgicalDescription','EmergencyDepartmentIndicator',  "APRSeverityofIllnessCode",
                            "HospitalCounty", "PaymentTypology1", "ZipCodedigits","APRDRGCode","APRMDCCode","Ethnicity",
                            "FacilityName"]
for col in columns_to_target_encode:
    uniq_vals = df[col].unique()
    # print(uniq_vals)
    ordinal_map = {value: ind for (ind, value) in enumerate(uniq_vals)}
    df[col] = df[col].map(ordinal_map)
X=df.loc[:, df.columns != 'LengthofStay']
Y=df.loc[:,'LengthofStay']
train_X = X.iloc[:r*9,:]
train_Y = Y.loc[:r*9]

# print(train_X)
target_encoding_dict = {}
for col in columns_to_target_encode:
    uniq_vals = df[col].unique()
    target_encoding_dict[col] = {}
    for val in uniq_vals:
        if (train_Y[train_X[col]==val].shape[0] != 0):

            mean_cost = np.mean(train_Y.loc[train_X[col]==val].values)
            median_cost = np.median(train_Y.loc[train_X[col]==val].values)

            target_encoding_dict[col][val] = mean_cost*median_cost
        else:
            target_encoding_dict[col][val] = 0
for col in columns_to_target_encode:
    df[col] = df[col].map(target_encoding_dict[col])
df

# @title Calcuting R2 values for differetn age group using catboost regressor
age_values_Count = df["AgeGroup"].value_counts()
print(age_values_Count)

age_values = df["AgeGroup"].unique()
print(age_values)

age_results = []

for actual_age in age_values:


    partial_df = df[df["AgeGroup"] == actual_age]
    frac = partial_df.shape[0] / df.shape[0]

    r = int(partial_df.shape[0] * 0.1)

    X=partial_df.loc[:, df.columns != 'LengthofStay']
    Y=partial_df.loc[:,'LengthofStay']

    train_X = X.iloc[:r*9,:].drop(columns=["AgeGroup"])
    train_Y = Y.iloc[:r*9]
    test_X = X.iloc[r*9:,:].drop(columns=["AgeGroup"])
    test_Y = Y.iloc[r*9:]

    X=X.drop(columns=["AgeGroup"])
    Y=Y.drop(columns=["AgeGroup"])

    clf = CatBoostRegressor(verbose = False)
    # clf.fit(train_X,train_Y)

    # Ypred = clf.predict(test_X)
    # r2 = metrics.r2_score(test_Y, Ypred)

    r2 = np.mean((cross_val_score(clf, X, Y, cv=10)))

    age_results.append([actual_age, frac, r2])
sorted_age = sorted(age_results, key= lambda x: -x[2])
print(sorted_age)

# @title Plots
plt.rcParams.update({'font.size': 30})
dfnew = pd.DataFrame(sorted_age, columns=["AgeGroup", "Fraction of dataset", "R2 score"])
dfnew.iloc[:, :].plot(y = "R2 score", x = "AgeGroup", kind='barh', legend=False)
fig = plt.gcf()

fig.set_size_inches(10, 13)
dfnew["Percentage of dataset"] = dfnew["Fraction of dataset"] * 100
dfnew.drop(columns=["Fraction of dataset"])
print(dfnew)

dfnew["Percentage of dataset"] = dfnew["Fraction of dataset"] * 100
dfnew.drop(columns=["Fraction of dataset"])
print(dfnew)

"""# Gender Wise"""

!pip install shap
!pip install catboost

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn import linear_model
import shap
from sklearn.tree import DecisionTreeRegressor
from sklearn import metrics
from sklearn import preprocessing
import math
from sklearn import tree
from matplotlib import pyplot as plt
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score
from sklearn import linear_model
import scipy.stats as ss
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
import itertools
from catboost import CatBoostRegressor
from catboost import CatBoostClassifier

df = pd.read_csv("https://health.data.ny.gov/api/views/4ny4-j5zv/rows.csv?accessType=DOWNLOAD")
r = int(df.shape[0] * 0.1)
print(r)

df = df.dropna(subset=['Hospital Service Area','Hospital County','Operating Certificate Number',
                      'Permanent Facility Id','Zip Code - 3 digits',
                      'APR Severity of Illness Description','APR Risk of Mortality'])
df.drop(['CCSR Diagnosis Description', 'CCSR Procedure Description','Discharge Year', 'APR DRG Description', 'APR MDC Description', 'Total Costs', 'Total Charges',
                 'APR Severity of Illness Description','Payment Typology 2','Payment Typology 3','Race','Birth Weight','Patient Disposition'], axis=1, inplace=True)

ga = math.pow(10,-15)
df.loc[:, 'Length of Stay'] = df['Length of Stay'].replace('120 +',120)
df.loc[:, 'Length of Stay'] = df['Length of Stay'].astype(np.int)

df = df.sample(frac=1)

names = df.columns
n = len(names)
i = 0
names1 = []
def remove(string):
  return string.replace(" ", "")
while(i < n):
     s = remove(names[i])
     if(s == "ZipCode-3digits"):
        s = "ZipCodedigits"
     names1.append(s)
     i = i+1


df.columns = names1

print(df.columns)

print(df.dtypes)

columns_to_target_encode = ["HospitalServiceArea", 'CCSRProcedureCode','CCSRDiagnosisCode','TypeofAdmission', 'APRRiskofMortality',
                            'APRMedicalSurgicalDescription','EmergencyDepartmentIndicator',  "AgeGroup", "APRSeverityofIllnessCode",
                            "HospitalCounty", "PaymentTypology1", "ZipCodedigits","APRDRGCode","APRMDCCode","Ethnicity",
                            "FacilityName"]

for col in columns_to_target_encode:
    uniq_vals = df[col].unique()
    # print(uniq_vals)
    ordinal_map = {value: ind for (ind, value) in enumerate(uniq_vals)}
    df[col] = df[col].map(ordinal_map)

X=df.loc[:, df.columns != 'LengthofStay']
Y=df.loc[:,'LengthofStay']

train_X = X.iloc[:r*9,:]
train_Y = Y.loc[:r*9]

# print(train_X)

target_encoding_dict = {}
for col in columns_to_target_encode:
    uniq_vals = df[col].unique()
    target_encoding_dict[col] = {}
    for val in uniq_vals:
        if (train_Y[train_X[col]==val].shape[0] != 0):

            mean_cost = np.mean(train_Y.loc[train_X[col]==val].values)
            median_cost = np.median(train_Y.loc[train_X[col]==val].values)

            target_encoding_dict[col][val] = mean_cost*median_cost
        else:
            target_encoding_dict[col][val] = 0

for col in columns_to_target_encode:
    df[col] = df[col].map(target_encoding_dict[col])
    gender_values_Count = df["Gender"].value_counts()

print(gender_values_Count)

gender_values = df["Gender"].unique()
print(gender_values)



gender_results = []

for actual_gender in gender_values:


    partial_df = df[df["Gender"] == actual_gender]
    frac = partial_df.shape[0] / df.shape[0]

    r = int(partial_df.shape[0] * 0.1)

    X=partial_df.loc[:, df.columns != 'LengthofStay']
    Y=partial_df.loc[:,'LengthofStay']
    train_X = X.iloc[:r*9,:].drop(columns=["Gender"])
    train_Y = Y.iloc[:r*9]
    test_X = X.iloc[r*9:,:].drop(columns=["Gender"])
    test_Y = Y.iloc[r*9:]

    X=X.drop(columns=["Gender"])
    Y=Y.drop(columns=["Gender"])

    clf = CatBoostRegressor(verbose = False)
    # clf.fit(train_X,train_Y)

    # Ypred = clf.predict(test_X)
    # r2 = metrics.r2_score(test_Y, Ypred)
    r2 = np.mean((cross_val_score(clf, X, Y, cv=10)))

    gender_results.append([actual_gender, frac, r2])

sorted_gender = sorted(gender_results, key= lambda x: -x[2])
print(sorted_gender)

plt.rcParams.update({'font.size': 30})
dfnew = pd.DataFrame(sorted_gender, columns=["Gender", "Fraction of dataset", "R2 score"])
dfnew.iloc[:, :].plot(y = "R2 score", x = "Gender", kind='barh', legend=False)
fig = plt.gcf()

fig.set_size_inches(15, 13)

dfnew["Percentage of dataset"] = dfnew["Fraction of dataset"] * 100
dfnew.drop(columns=["Fraction of dataset"])
print(dfnew)





"""# Race Wise"""

!pip install shap
!pip install catboost

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn import linear_model
import shap
from sklearn.tree import DecisionTreeRegressor
from sklearn import metrics
from sklearn import preprocessing

from sklearn import tree
from matplotlib import pyplot as plt
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score
from sklearn import linear_model
import scipy.stats as ss
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
import itertools
from catboost import CatBoostRegressor
from catboost import CatBoostClassifier

df = pd.read_csv("https://health.data.ny.gov/api/views/4ny4-j5zv/rows.csv?accessType=DOWNLOAD")
r = int(df.shape[0] * 0.1)
print(r)

df = df.dropna(subset=['Hospital Service Area','Hospital County','Operating Certificate Number',
                      'Permanent Facility Id','Zip Code - 3 digits',
                      'APR Severity of Illness Description','APR Risk of Mortality'])
df.drop(['CCSR Diagnosis Description', 'CCSR Procedure Description','Discharge Year', 'APR DRG Description', 'APR MDC Description', 'Total Costs', 'Total Charges',
                 'APR Severity of Illness Description','Payment Typology 2','Payment Typology 3','Gender','Birth Weight','Patient Disposition'], axis=1, inplace=True)

ga = math.pow(10,-15)
df.loc[:, 'Length of Stay'] = df['Length of Stay'].replace('120 +',120)
df.loc[:, 'Length of Stay'] = df['Length of Stay'].astype(np.int)

df = df.sample(frac=1)

names = df.columns
n = len(names)
i = 0
names1 = []
def remove(string):
  return string.replace(" ", "")
while(i < n):
     s = remove(names[i])
     if(s == "ZipCode-3digits"):
        s = "ZipCodedigits"
     names1.append(s)
     i = i+1


df.columns = names1

print(df.columns)

print(df.dtypes)

columns_to_target_encode = ["HospitalServiceArea", 'CCSRProcedureCode','CCSRDiagnosisCode','TypeofAdmission', 'APRRiskofMortality',
                            'APRMedicalSurgicalDescription','EmergencyDepartmentIndicator',  "AgeGroup", "APRSeverityofIllnessCode",
                            "HospitalCounty", "PaymentTypology1", "ZipCodedigits","APRDRGCode","APRMDCCode","Ethnicity",
                            "FacilityName"]

for col in columns_to_target_encode:
    uniq_vals = df[col].unique()
    # print(uniq_vals)
    ordinal_map = {value: ind for (ind, value) in enumerate(uniq_vals)}
    df[col] = df[col].map(ordinal_map)

X=df.loc[:, df.columns != 'LengthofStay']
Y=df.loc[:,'LengthofStay']
train_X = X.iloc[:r*9,:]
train_Y = Y.loc[:r*9]

target_encoding_dict = {}
for col in columns_to_target_encode:
    uniq_vals = df[col].unique()
    target_encoding_dict[col] = {}
    for val in uniq_vals:
        if (train_Y[train_X[col]==val].shape[0] != 0):

            mean_cost = np.mean(train_Y.loc[train_X[col]==val].values)
            median_cost = np.median(train_Y.loc[train_X[col]==val].values)

            target_encoding_dict[col][val] = mean_cost*median_cost
        else:
            target_encoding_dict[col][val] = 0

for col in columns_to_target_encode:
    df[col] = df[col].map(target_encoding_dict[col])
    gender_values_Count = df["Race"].value_counts()

print(gender_values_Count)

gender_values = df["Race"].unique()
print(gender_values)

gender_results = []

for actual_gender in gender_values:


    partial_df = df[df["Race"] == actual_gender]
    frac = partial_df.shape[0] / df.shape[0]

    r = int(partial_df.shape[0] * 0.1)

    X=partial_df.loc[:, df.columns != 'LengthofStay']
    Y=partial_df.loc[:,'LengthofStay']
    # train_X = X.iloc[:r*9,:].drop(columns=["Race"])
    # train_Y = Y.iloc[:r*9]
    # test_X = X.iloc[r*9:,:].drop(columns=["Race"])
    # test_Y = Y.iloc[r*9:]

    X=X.drop(columns=["Race"])
    Y=Y.drop(columns=["Race"])


    clf = CatBoostRegressor(verbose = False)
    # clf.fit(train_X,train_Y)

    # Ypred = clf.predict(test_X)
    # r2 = metrics.r2_score(test_Y, Ypred)

    r2 = np.mean((cross_val_score(clf, X, Y, cv=10)))

    gender_results.append([actual_gender, frac, r2])

sorted_gender = sorted(gender_results, key= lambda x: -x[2])
print(sorted_gender)

plt.rcParams.update({'font.size': 30})
dfnew = pd.DataFrame(sorted_gender, columns=["Race", "Fraction of dataset", "R2 score"])
dfnew.iloc[:, :].plot(y = "R2 score", x = "Race", kind='barh', legend=False)
fig = plt.gcf()

fig.set_size_inches(15, 13)

dfnew["Percentage of dataset"] = dfnew["Fraction of dataset"] * 100
dfnew.drop(columns=["Fraction of dataset"])
print(dfnew)

"""# Predicting LOS wihout using patient dispostion for three type of regressor"""

# @title Imports
!pip install shap
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim

from torch.utils.data import Dataset,DataLoader, random_split
from sklearn import metrics
import math
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import cross_val_score

# @title Data preprocessing
df = pd.read_csv("https://health.data.ny.gov/api/views/4ny4-j5zv/rows.csv?accessType=DOWNLOAD")


r = int(df.shape[0] * 0.1)
print(r)
df['Hospital County'].unique()
df['Hospital Service Area'].unique()
df = df.dropna(subset=['Hospital Service Area','Hospital County','Operating Certificate Number',
                      'Permanent Facility Id','Zip Code - 3 digits',
                      'APR Severity of Illness Description','APR Risk of Mortality'])
df.drop(['CCSR Diagnosis Description', 'CCSR Procedure Description','Discharge Year', 'APR DRG Description', 'APR MDC Description', 'Total Costs', 'Total Charges',
                 'APR Severity of Illness Description','Payment Typology 2','Payment Typology 3','Race','Gender','Birth Weight','Patient Disposition'], axis=1, inplace=True)

ga = math.pow(10,-15)
df.loc[:, 'Length of Stay'] = df['Length of Stay'].replace('120 +',120)
df.loc[:, 'Length of Stay'] = df['Length of Stay'].astype(np.int)

df = df.sample(frac=1)

names = df.columns
n = len(names)
i = 0
names1 = []
def remove(string):
  return string.replace(" ", "")
while(i < n):
     s = remove(names[i])
     if(s == "ZipCode-3digits"):
        s = "ZipCodedigits"
     names1.append(s)
     i = i+1


df.columns = names1

# @title Data transforming using target encoding
columns_to_target_encode = ["HospitalServiceArea", 'CCSRProcedureCode','CCSRDiagnosisCode','TypeofAdmission', 'APRRiskofMortality',
                            'APRMedicalSurgicalDescription','EmergencyDepartmentIndicator',  "AgeGroup", "APRSeverityofIllnessCode",
                            "HospitalCounty", "PaymentTypology1", "ZipCodedigits","APRDRGCode","APRMDCCode","Ethnicity",
                            "FacilityName"]
for col in columns_to_target_encode:
    uniq_vals = df[col].unique()
    print(uniq_vals)
    ordinal_map = {value: ind for (ind, value) in enumerate(uniq_vals)}
    df[col] = df[col].map(ordinal_map)
print(df.shape)
print(r)
X=df.loc[:, df.columns != 'LengthofStay']
Y=df.loc[:,'LengthofStay']
train_X = X.iloc[:r*9,:]
train_Y = Y.loc[:r*9]

target_encoding_dict = {}
for col in columns_to_target_encode:
    uniq_vals = df[col].unique()
    target_encoding_dict[col] = {}
    for val in uniq_vals:
        if (train_Y[train_X[col]==val].shape[0] != 0):

            mean_cost = np.mean(train_Y.loc[train_X[col]==val].values)
            median_cost = np.median(train_Y.loc[train_X[col]==val].values)

            target_encoding_dict[col][val] = mean_cost*median_cost
        else:
            target_encoding_dict[col][val] = 0
for col in columns_to_target_encode:
    df[col] = df[col].map(target_encoding_dict[col])
df

# @title Creating datasets for train and test
X=df.loc[:, df.columns != 'LengthofStay'].values
Y=df.loc[:,'LengthofStay'].values
train_X = X[:r*9,:]
train_Y = Y[:r*9]
test_X = X[r*9:,:]
test_Y = Y[r*9:]

# @title R2 values using random forest
clf = RandomForestRegressor(max_depth=10,n_estimators=10)
clf.fit(train_X,train_Y)
r2 = clf.score(test_X, test_Y)
print(f"r2 score = {r2}")
cv_score1 = np.mean((cross_val_score(clf, X, Y, cv=10)))
print(f"cross validation score using random forest regressor {cv_score1}")

# @title R2 values using XGBoost
!pip install xgboost
import xgboost as xg
xgb_r = xg.XGBRegressor(objective ='reg:linear', n_estimators = 10, seed = 123)
xgb_r.fit(train_X, train_Y)
pred = xgb_r.predict(test_X)
r2 = metrics.r2_score(test_Y, pred)
print(f"r2 score = {r2}")
cv_score2 = np.mean((cross_val_score(xgb_r, X, Y, cv=10)))
print(f"cross validation score using xgboost regressor {cv_score2}")

# @title R2 values using Decision Tree
from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import cross_val_score
regressor = DecisionTreeRegressor(random_state=0, max_depth=10, max_features="auto")
regressor.fit(train_X, train_Y, check_input=True)
pred = regressor.predict(test_X)
r2 = metrics.r2_score(test_Y, pred)
print(f"r2 score = {r2}")
cv_score3 = np.mean((cross_val_score(regressor, X, Y, cv=10)))
print(f"cross validation score using Decision Tree regressor {cv_score3}")

"""# Gepspatial Information"""

!pip install geopandas

import pandas as pd
import matplotlib.pyplot as plt
import geopandas as gpd

fp = "/content/sample_data/new-york-zip-codes-_1604.shp"
map_df = gpd.read_file(fp)
map_df.plot()

map_df.head()

csv_file = pd.read_csv('/content/sample_data/uszips.csv')
csv_file.zip = csv_file.zip.astype(int)
csv_file.head()

map_df.rename(columns={'ZCTA5CE10': 'zip'}, inplace=True)
map_df.zip = map_df.zip.astype(int)
map_df.head()

joined_map = map_df.merge(csv_file, left_on='zip', right_on='zip', how='inner')

joined_map.head()

joined_map.columns

joined_map.rename(columns={'zip': 'zip code'}, inplace=True)
joined_map.plot()

joined_map['zip'] = joined_map['zip code'].astype(str).str[:3]
map = joined_map[['geometry', 'zip', 'population']].dissolve(by='zip', aggfunc='sum')
map.reset_index(inplace=True)
map.zip = map.zip.astype(int)
map

map.plot()

df = pd.read_csv("https://health.data.ny.gov/api/views/4ny4-j5zv/rows.csv?accessType=DOWNLOAD")

df.head()

grouped_df = df.groupby(['Zip Code - 3 digits', 'APR DRG Code']).size().reset_index(name='patient_count')

# Step 4 (Optional): Filter to a specific disease code
disease_code_to_analyze = 362
# create dictionary storing number of occurances of each disease
# index with APR DRG Code column
#diseases = {}
#tdf = df.iloc()
#n = 18
#for index, row in df.iterrows():
 #       if row[18] in diseases:
  #          diseases[row[18]] += 1
   #     else:
    #        diseases[row[18]] = 1

filtered_df = grouped_df.loc[grouped_df['APR DRG Code'] == disease_code_to_analyze]

# Step 5: Print the resulting DataFrame
filtered_df
#print(diseases)

filtered_df.rename(columns={'Zip Code - 3 digits': 'zip'}, inplace=True)
value_to_remove = 'OOS'
filtered_df = filtered_df[filtered_df['zip'] != value_to_remove]
filtered_df.zip = filtered_df.zip.astype(int)
filtered_df.head()

disease_map = map.merge(filtered_df, left_on='zip', right_on='zip', how='inner')
disease_map.head()

disease_map['patient_count per 100,000 people'] = disease_map['patient_count'] / disease_map['population']
constant = 100000
disease_map['patient_count per 100,000 people'] = disease_map['patient_count per 100,000 people'] * constant

disease_map.head()

disease_map

# bins = [0, 50, 100, 200, 500]  # Define your own bin edges
# labels = ['0-5', '5-15', '15-50', '50-200']

# # Create a new column in the GeoDataFrame with the categorical data
# disease_map['data_range'] = pd.cut(disease_map['patient_count per 100,000 people'], bins=bins, labels=labels, right=False)

fig, ax = plt.subplots(1, figsize=(10, 6))
vmin= 0
vmax = disease_map['patient_count per 100,000 people'].max()
ax.axis('off')
# add a title
ax.set_title('Breast Cancer', fontdict={'fontsize': '25', 'fontweight' : '3'})
# create an annotation for the data source
ax.annotate('Source: SPARCS, 2019',xy=(0.1, .08), xycoords='figure fraction', horizontalalignment='left', verticalalignment='top', fontsize=12, color='#555555')
# Create colorbar as a legend
sm = plt.cm.ScalarMappable(cmap='Reds', norm=plt.Normalize(vmin=vmin, vmax=vmax))
# empty array for the data range
sm._A = []
# add the colorbar to the figure
cbar = fig.colorbar(sm)


disease_map.plot(column='patient_count per 100,000 people', cmap='Reds', linewidth=0.8, ax=ax, edgecolor='0.8')

df2=disease_map.loc[disease_map['patient_count per 100,000 people'].idxmax()]
print(df2)

#find the number of patients with disease code in every zip code and store in a different dataframe. merge it with map and then create map

#read the SPARCS file and select zip code, APR DRG CODE columns

#truncate the zip codes to 3 digits

#join the data with map df along zip

#get population data

#join it and get per